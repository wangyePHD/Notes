## 00 Multifold
1. PointGame: Geometrically and Adaptively Masked Auto-Encoder on Point Clouds, 2023.03.23
    * 有些类似
2. Mask Hierarchical Features For Self-Supervised Learning, 2023.04.01
    * 特征层面的multifold，不够简洁，但说明了multifold在feature层面是有用的
3. PixMIM: Rethinking Pixel Reconstruction in Masked Image Modeling, 2023.03.14 
    * 可能有用，重点看文章的insight
4. Efficient Masked Autoencoders with Self-Consistency， 2023.02.28
    * Multifold 
5. SdAE: Self-distillated Masked Autoencoder, ECCV2022
    * 出现了multifold views
6. Multi-View Masked World Models for Visual Robotic Manipulation, 2023.02.05
    * multiview
7. Masked autoencoders are effective solution to transformer data-hungry，2023.01.10
8. A SIMPLE, EFFICIENT AND SCALABLE CONTRASTIVE MASKED AUTOENCODER FOR LEARNING VISUAL REPRESENTATIONS，2022.10.30
9. Masked Contrastive Representation Learning，2022.11.11
10. Multimodal Masked Autoencoders Learn Transferable Representations，2022.10.21
11. Masked Autoencoders are Robust Data Augmentors，2022.06.10
12. Contrastive Masked Autoencoders are Stronger Vision Learners，2022.11.28
13. Understanding Masked Image Modeling via Learning Occlusion Invariant Feature,2022.08.08



## 01 掩码策略
1. Multi-Modal Representation Learning with Text-Driven Soft Masks, 2023.04.03
2. Mask Hierarchical Features For Self-Supervised Learning, 2023.04.01
    * 特征层面的multifold，不够简洁，但说明了multifold在feature层面是有用的。
3. VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking, 2023.03.29
4. Improving Masked Autoencoders by Learning Where to Mask, 2023.03.12
5. ConMAE: Contour Guided MAE for Unsupervised Vehicle Re-Identification, 2023.02.11
    * Contour guided
6. Label Mask AutoEncoder(L-MAE): A Pure Transformer Method to Augment Semantic Segmentation Datasets， 2022.11.21
7. Object-wise Masked Autoencoders for Fast Pre-training，2022.03.28
8. SemMAE: Semantic-Guided Masking for Learning Masked Autoencoders，2022.10.05


## 02 视频领域
1. DropMAE: Masked Autoencoders with Spatial-Attention Dropout for Tracking Tasks，2023.04.02
    * 引入时序关系学习
2. Unlocking Masked Autoencoders as Loss Function for Image and Video Restoration, 2023.03.29


## 03 数据增强
1. Mixed Autoencoder for Self-supervised Visual Representation Learning, 2023.03.30

## 04 Architecture
1. Masked Autoencoders as Image Processors, 2023.03.30
2. Denoising Diffusion Autoencoders are Unified Self-supervised Learners, 2023.03.17
3. Generic-to-Specific Distillation of Masked Autoencoders, 2023.02.28
4. PixMIM: Rethinking Pixel Reconstruction in Masked Image Modeling, 2023.03.24
5. MOMA: Distill from Self-Supervised Teachers，2023.02.04
    * 蒸馏
6. Swin MAE: Masked Autoencoders for Small Datasets，2023.01.05
7. Improving Visual Representation Learning through Perceptual Understanding， 2023.03.28
8. GD-MAE: Generative Decoder for MAE Pre-training on LiDAR Point Clouds，2023.03.17
9. SMAUG: Sparse Masked Autoencoder for Efficient Video-Language Pre-training，2022.11.30
10. CAE v2: Context Autoencoder with CLIP Target，2022.11.17
11. Stare at What You See: Masked Image Modeling without Reconstruction，2023.03.16
12. SupMAE: Supervised Masked Autoencoders Are Efficient Vision Learners，2022.08.16
13. VLMAE: Vision-Language Masked Autoencoder,2022.08.19

## 05 结合对比学习
1. Visual Representation Learning from Unlabeled Video using Contrastive Masked Autoencoders, 2023.03.21
2. MCAE: Masked Contrastive Autoencoder for Face Anti-Spoofing， 2023.02.17
3. CMAE-V: Contrastive Masked Autoencoders for Video Action Recognition，2023.01.15
4. Masked Contrastive Representation Learning，2022.11.11
5. Contrastive Masked Autoencoders are Stronger Vision Learners，2022.11.28

## 06 3D
1. PiMAE: Point Cloud and Image Interactive Masked Autoencoders for 3D Object Detection, 2023.03.14
2. Joint-MAE: 2D-3D Joint Masked Autoencoders for 3D Point Cloud Pre-training，2023.03.30
    * 训练在ShapeNet上，应该说是第一个cross-model image&pointcloud的Mask learning工作，没有代码release
3. AUTOENCODERS AS CROSS-MODAL TEACHERS: CAN PRETRAINED 2D IMAGE TRANSFORMERS HELP 3D REPRESENTATION LEARNING，2023.02.02
4. MAELi - Masked Autoencoder for Large-Scale LiDAR Point Clouds，2023.03.17
5. Learning 3D Representations from 2D Pre-trained Models via Image-to-Point Masked Autoencoders，2022.12.13
6. BEV-MAE: Bird’s Eye View Masked Autoencoders for Outdoor Point Cloud Pre-training
7. GD-MAE: Generative Decoder for MAE Pre-training on LiDAR Point Clouds，2023.03.17
8. Point-MA2E: Masked and Affine Transformed AutoEncoder for Self-supervised Point Cloud Learning，2023.03.18
9. Voxel-MAE: Masked Autoencoders for Self-supervised Pre-training Large-scale，2022.11.23
10. Masked Autoencoder for Self-Supervised Pre-training on Lidar Point Clouds，2023.03.09
11. MeshMAE: Masked Autoencoders for 3D Mesh Data Analysis，2022.11.11
